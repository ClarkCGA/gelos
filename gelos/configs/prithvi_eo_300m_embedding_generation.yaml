# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  callbacks: []
  max_epochs: 0

data:
  class_path: gelos.gelosdatamodule.GELOSDataModule
  init_args:
    batch_size: 1
    num_workers: 0
    bands:
      S2L2A:
        - BLUE
        - GREEN
        - RED
        - NIR_NARROW
        - SWIR_1
        - SWIR_2

model:
  class_path: terratorch.tasks.EmbeddingGenerationTask
  title: Prithvi EO V2 300M
  init_args:
    model: prithvi_eo_v2_300
    model_args:
      backbone: prithvi_eo_v2_300
      backbone_pretrained: true
      backbone_bands:
        - BLUE
        - GREEN
        - RED
        - NIR_NARROW
        - SWIR_1
        - SWIR_2
    output_format: parquet
    embed_file_key: filename 
    # layers: [-1] # Model layers to extract embeddings from, -1 means the last layer
    embedding_pooling: null 
    has_cls: True
    # temporal_cfg: 
    #   temporal_wrapper: True
    #   temporal_pooling: keep

# define embedding extraction strategy names and lists of arguments for the embedding extraction function
embedding_extraction_strategies:
  CLS Token:
    - start: 0
      stop: 1
      step: 1
  All Steps of Middle Patch:
 # as the first patch is the cls token, we index the middle as 19 rather than 18.
 # this is important for consistency with non-cls token models like terramind.
    - start: 19
      stop: null
      # start and step are determined by the patch H and W dimensions determined by the model and the input sizes.
      # in this case, as our inputs are 96x96 and prithvi eo 300m uses 16x16 patches, we have 36 patches per time step.
      step: 36
  All Patches from April to June:
    - start: 37
      stop: 73
      step: 1
  # All Embeddings:
  #   - start: 0
  #     stop: null
  #     step: 1