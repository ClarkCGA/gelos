{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77bc98a7",
   "metadata": {},
   "source": [
    "# Probe label accuracy and homogeneity using a k-NN classifier\n",
    "\n",
    "This notebook walks through the process of extracting generated embeddings and using them to train a k-NN classifier. This is applied to the input data in order to quantify class separability in the embeddings and to identify labels that are challenging or incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafa171",
   "metadata": {},
   "source": [
    "## Define parameters for embedding extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fba41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from gelos.embedding_extraction import extract_embeddings\n",
    "from gelos.embedding_generation import perturb_args_to_string\n",
    "import geopandas as gpd\n",
    "import yaml\n",
    "from gelos.config import PROJ_ROOT, PROCESSED_DATA_DIR, DATA_VERSION, RAW_DATA_DIR\n",
    "from gelos.config import REPORTS_DIR, FIGURES_DIR\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "try:\n",
    "    import faiss  # fast k-NN for high-dimensional data\n",
    "    _faiss_available = True\n",
    "except ImportError:\n",
    "    faiss = None\n",
    "    _faiss_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fbf0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 4\n",
    "config_yaml_names = [\n",
    "    \"prithvieov2300_noperturb.yaml\",\n",
    "    \"prithvieov2600_noperturb.yaml\",\n",
    "    \"terramindv1base_noperturb.yaml\",\n",
    "    # add more configs here\n",
    "]\n",
    "# extraction_strategy = \"All Steps of Middle Patch\"\n",
    "max_workers = None  # set to an int to cap parallelism\n",
    "n_neighbors = 5\n",
    "fast_knn_method = \"faiss\"  # options: \"faiss\" (if available) or \"sklearn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab53263",
   "metadata": {},
   "source": [
    "## Extract embeddings and train a k-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e0f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _l2_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    norms = np.linalg.norm(x, axis=1, keepdims=True) + 1e-12\n",
    "    return x / norms\n",
    "\n",
    "def _faiss_knn_predict(train_X: np.ndarray, train_y: np.ndarray, test_X: np.ndarray, k: int) -> np.ndarray:\n",
    "    dim = train_X.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(train_X.astype(np.float32))\n",
    "    sims, idx = index.search(test_X.astype(np.float32), k)\n",
    "    top_labels = train_y[idx]\n",
    "    preds = []\n",
    "    for row in top_labels:\n",
    "        vals, counts = np.unique(row, return_counts=True)\n",
    "        preds.append(vals[np.argmax(counts)])\n",
    "    return np.array(preds, dtype=train_y.dtype)\n",
    "\n",
    "def run_config(yaml_name: str, extraction_strategy: str, knn_method: str = \"faiss\", n_neighbors: int = 5):\n",
    "    yaml_path = PROJ_ROOT / \"gelos\" / \"configs\" / yaml_name\n",
    "    with open(yaml_path, \"r\") as f:\n",
    "        yaml_config = yaml.safe_load(f)\n",
    "    data_root = RAW_DATA_DIR / DATA_VERSION\n",
    "    chip_gdf = gpd.read_file(data_root / \"gelos_chip_tracker.geojson\")\n",
    "    figures_dir = FIGURES_DIR / DATA_VERSION\n",
    "    figures_dir.mkdir(exist_ok=True, parents=True)\n",
    "    model_name = yaml_config[\"model\"][\"init_args\"][\"model\"]\n",
    "    model_title = yaml_config[\"model\"][\"title\"]\n",
    "    embedding_extraction_strategies = yaml_config[\"embedding_extraction_strategies\"]\n",
    "    perturb = yaml_config[\"data\"][\"init_args\"].get(\"perturb_bands\", None)\n",
    "    perturb_string = perturb_args_to_string(perturb)\n",
    "    output_dir = PROCESSED_DATA_DIR / DATA_VERSION / model_name / perturb_string\n",
    "    embeddings_directories = [item for item in output_dir.iterdir() if item.is_dir()]\n",
    "    if not embeddings_directories:\n",
    "        raise FileNotFoundError(f\"No embeddings directories found for {yaml_name}\")\n",
    "    embeddings_directory = embeddings_directories[0]\n",
    "    slice_args = embedding_extraction_strategies[extraction_strategy]\n",
    "    embeddings, chip_indices = extract_embeddings(embeddings_directory, slice_args=slice_args)\n",
    "    label_col = \"category\"  # <-- set to the column in chip_gdf containing class labels\n",
    "    labels = chip_gdf.iloc[chip_indices][label_col].to_numpy()\n",
    "    use_faiss = knn_method == \"faiss\" and _faiss_available\n",
    "    X = _l2_normalize(embeddings) if use_faiss else embeddings\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = np.empty_like(labels)\n",
    "    for _, (train_idx, test_idx) in enumerate(tqdm(cv.split(X, labels), total=cv.get_n_splits(), desc=f\"{yaml_name} folds\")):\n",
    "        if use_faiss:\n",
    "            y_pred[test_idx] = _faiss_knn_predict(X[train_idx], labels[train_idx], X[test_idx], n_neighbors)\n",
    "        else:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "            knn.fit(X[train_idx], labels[train_idx])\n",
    "            y_pred[test_idx] = knn.predict(X[test_idx])\n",
    "    overall_acc = accuracy_score(labels, y_pred)\n",
    "    cm = confusion_matrix(labels, y_pred, labels=np.unique(labels))\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    per_class = dict(zip(np.unique(labels), per_class_acc))\n",
    "    return yaml_name, extraction_strategy, model_title, overall_acc, per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434429bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f6aa487",
   "metadata": {},
   "source": [
    "## Visualize examples with high and low accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75dfb31",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
