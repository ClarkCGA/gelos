{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde96234",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7e0996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-26 00:49:48.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgelos.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /app\u001b[0m\n",
      "/opt/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n",
      "/opt/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/opt/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from gelos.gelosdataset import GELOSDataSet\n",
    "from gelos.gelosdatamodule import GELOSDataModule\n",
    "import yaml\n",
    "from gelos import config\n",
    "from lightning.pytorch import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c71c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  class_path: gelos.gelosdatamodule.GELOSDataModule\n",
      "  init_args:\n",
      "    bands:\n",
      "      DEM:\n",
      "      - DEM\n",
      "      S1RTC:\n",
      "      - VV\n",
      "      - VH\n",
      "      S2L2A:\n",
      "      - COASTAL_AEROSOL\n",
      "      - BLUE\n",
      "      - GREEN\n",
      "      - RED\n",
      "      - RED_EDGE_1\n",
      "      - RED_EDGE_2\n",
      "      - RED_EDGE_3\n",
      "      - NIR_BROAD\n",
      "      - NIR_NARROW\n",
      "      - WATER_VAPOR\n",
      "      - SWIR_1\n",
      "      - SWIR_2\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    repeat_bands:\n",
      "      DEM: 4\n",
      "    target_size: 96\n",
      "model:\n",
      "  class_path: terratorch.tasks.EmbeddingGenerationTask\n",
      "  init_args:\n",
      "    embed_file_key: filename\n",
      "    embedding_pooling: null\n",
      "    has_cls: false\n",
      "    layers:\n",
      "    - -1\n",
      "    model: terramind_v1_base\n",
      "    model_args:\n",
      "      merge_method: mean\n",
      "      modalities:\n",
      "      - S2L2A\n",
      "      - S1RTC\n",
      "      - DEM\n",
      "      pretrained: true\n",
      "    output_format: parquet\n",
      "    temporal_cfg:\n",
      "      temporal_pooling: keep\n",
      "      temporal_wrapper: true\n",
      "seed_everything: 0\n",
      "trainer:\n",
      "  accelerator: auto\n",
      "  callbacks: []\n",
      "  devices: auto\n",
      "  max_epochs: 0\n",
      "  num_nodes: 1\n",
      "  strategy: auto\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_config_directory = config.PROJ_ROOT / 'gelos' / 'configs'\n",
    "yaml_name = 'terramind_embedding_generation.yaml'\n",
    "with open(yaml_config_directory / yaml_name, \"r\") as f:\n",
    "    yaml_config = yaml.safe_load(f)\n",
    "print(yaml.dump(yaml_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203451e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = yaml_config['model']['init_args']['model']\n",
    "output_dir = config.INTERIM_DATA_DIR / config.DATA_VERSION / model_name\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "data_root = config.RAW_DATA_DIR / config.DATA_VERSION\n",
    "\n",
    "# add variables to yaml config so it can be passed to classes\n",
    "yaml_config['data']['init_args']['data_root'] = data_root\n",
    "yaml_config['model']['init_args']['output_dir'] = output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63116cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gelos_datamodule = GELOSDataModule(**yaml_config['data']['init_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5e297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from terratorch.tasks import EmbeddingGenerationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4a3b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/terratorch/tasks/embedding_generation.py:67: UserWarning: GeoTIFF selected; 2D token embeddings (ViT) will be reshaped to [C, sqrt(num_tokens), sqrt(num_tokens)] after dropping CLS if present.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "task = EmbeddingGenerationTask(**yaml_config['model']['init_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51dfd5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "INFO: GPU available: False, used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fbf96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/76822 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`file_ids` shape mismatch: expected (1, 4), got (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgelos_datamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:887\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    886\u001b[39m \u001b[38;5;28mself\u001b[39m.predicting = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:928\u001b[39m, in \u001b[36mTrainer._predict_impl\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[39m\n\u001b[32m    924\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    925\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    926\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    927\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    931\u001b[39m \u001b[38;5;28mself\u001b[39m.predicting = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1051\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._evaluation_loop.run()\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predicting:\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m   1053\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     context_manager = torch.no_grad\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/loops/prediction_loop.py:125\u001b[39m, in \u001b[36m_PredictionLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_progress.is_last_batch = data_fetcher.done\n\u001b[32m    124\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/loops/prediction_loop.py:255\u001b[39m, in \u001b[36m_PredictionLoop._predict_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# configure step_kwargs\u001b[39;00m\n\u001b[32m    250\u001b[39m step_args = (\n\u001b[32m    251\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, \u001b[33m\"\u001b[39m\u001b[33mpredict_step\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    254\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m predictions = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredict_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    257\u001b[39m     \u001b[38;5;28mself\u001b[39m._warning_cache.warn(\u001b[33m\"\u001b[39m\u001b[33mpredict returned None if it was on purpose, ignore this warning...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    331\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:438\u001b[39m, in \u001b[36mStrategy.predict_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model != \u001b[38;5;28mself\u001b[39m.lightning_module:\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mpredict_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/terratorch/tasks/embedding_generation.py:173\u001b[39m, in \u001b[36mEmbeddingGenerationTask.predict_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[32m    171\u001b[39m         metadata = \u001b[38;5;28mself\u001b[39m.pull_metadata(batch)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_file_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m embeddings, layers = \u001b[38;5;28mself\u001b[39m.get_embeddings(x, \u001b[38;5;28mself\u001b[39m.layers)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m embedding, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(embeddings, layers):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/terratorch/tasks/embedding_generation.py:95\u001b[39m, in \u001b[36mEmbeddingGenerationTask.check_file_ids\u001b[39m\u001b[34m(self, file_ids, x)\u001b[39m\n\u001b[32m     93\u001b[39m     expected = (B,) \u001b[38;5;28;01mif\u001b[39;00m T == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (B, T)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(file_ids.shape) != expected:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`file_ids` shape mismatch: expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(file_ids.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_ids, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[31mValueError\u001b[39m: `file_ids` shape mismatch: expected (1, 4), got (1,)"
     ]
    }
   ],
   "source": [
    "trainer.predict(model=task, datamodule=gelos_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6afcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
