{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb27a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from gelos.config import PROCESSED_DATA_DIR, DATA_DIR, DATA_VERSION, RAW_DATA_DIR\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from gelos import config\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d22044ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  class_path: gelos.gelosdatamodule.GELOSDataModule\n",
      "  init_args:\n",
      "    bands:\n",
      "      DEM:\n",
      "      - DEM\n",
      "      S1RTC:\n",
      "      - VV\n",
      "      - VH\n",
      "      S2L2A:\n",
      "      - COASTAL_AEROSOL\n",
      "      - BLUE\n",
      "      - GREEN\n",
      "      - RED\n",
      "      - RED_EDGE_1\n",
      "      - RED_EDGE_2\n",
      "      - RED_EDGE_3\n",
      "      - NIR_BROAD\n",
      "      - NIR_NARROW\n",
      "      - WATER_VAPOR\n",
      "      - SWIR_1\n",
      "      - SWIR_2\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    repeat_bands:\n",
      "      DEM: 4\n",
      "    target_size: 96\n",
      "embedding_extraction_strategies:\n",
      "  All Embeddings:\n",
      "  - start: 0\n",
      "    step: 1\n",
      "    stop: null\n",
      "  All Patches from April to June:\n",
      "  - start: 1\n",
      "    step: 1\n",
      "    stop: 2\n",
      "  All Steps of Middle Patch:\n",
      "  - start: 0\n",
      "    step: 1\n",
      "    stop: null\n",
      "  - start: 18\n",
      "    step: 1\n",
      "    stop: 19\n",
      "model:\n",
      "  class_path: terratorch.tasks.EmbeddingGenerationTask\n",
      "  init_args:\n",
      "    embed_file_key: filename\n",
      "    embedding_pooling: null\n",
      "    has_cls: false\n",
      "    layers:\n",
      "    - -1\n",
      "    model: terramind_v1_base\n",
      "    model_args:\n",
      "      merge_method: mean\n",
      "      modalities:\n",
      "      - S2L2A\n",
      "      - S1RTC\n",
      "      - DEM\n",
      "      pretrained: true\n",
      "    output_format: parquet\n",
      "    temporal_cfg:\n",
      "      temporal_pooling: keep\n",
      "      temporal_wrapper: true\n",
      "  title: Terramind V1 Base\n",
      "seed_everything: 0\n",
      "trainer:\n",
      "  accelerator: auto\n",
      "  callbacks: []\n",
      "  devices: auto\n",
      "  max_epochs: 0\n",
      "  num_nodes: 1\n",
      "  strategy: auto\n",
      "\n",
      "/app/data/processed/v0.50.0/terramind_v1_base/layer_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 11950/60507 [05:52<23:50, 33.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m file_id = \u001b[38;5;28mint\u001b[39m(file.stem.split(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m])  \u001b[38;5;66;03m# 0000 -> 0\u001b[39;00m\n\u001b[32m     20\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] = file_id\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/pandas/core/frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/pandas/io/parquet.py:482\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m impl = get_engine(engine)\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io.BytesIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/pandas/io/parquet.py:229\u001b[39m, in \u001b[36mPyArrowImpl.write\u001b[39m\u001b[34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mself\u001b[39m.api.parquet.write_to_dataset(\n\u001b[32m    220\u001b[39m             table,\n\u001b[32m    221\u001b[39m             path_or_handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m             **kwargs,\n\u001b[32m    226\u001b[39m         )\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    228\u001b[39m         \u001b[38;5;66;03m# write to single output file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/pyarrow/parquet/core.py:1984\u001b[39m, in \u001b[36mwrite_table\u001b[39m\u001b[34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, store_decimal_as_integer, **kwargs)\u001b[39m\n\u001b[32m   1957\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1958\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ParquetWriter(\n\u001b[32m   1959\u001b[39m             where, table.schema,\n\u001b[32m   1960\u001b[39m             filesystem=filesystem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1982\u001b[39m             store_decimal_as_integer=store_decimal_as_integer,\n\u001b[32m   1983\u001b[39m             **kwargs) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m-> \u001b[39m\u001b[32m1984\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1986\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(where):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.11/site-packages/pyarrow/parquet/core.py:1166\u001b[39m, in \u001b[36mParquetWriter.write_table\u001b[39m\u001b[34m(self, table, row_group_size)\u001b[39m\n\u001b[32m   1160\u001b[39m     msg = (\n\u001b[32m   1161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTable schema does not match schema used to create file: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtable:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtable.schema\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m vs. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfile:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.schema\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1163\u001b[39m     )\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "yaml_config_directory = config.PROJ_ROOT / 'gelos' / 'configs'\n",
    "for yaml_filepath in yaml_config_directory.glob(\"*.yaml\"):\n",
    "    with open(yaml_filepath, \"r\") as f:\n",
    "        yaml_config = yaml.safe_load(f)\n",
    "    print(yaml.dump(yaml_config))\n",
    "    model_name = yaml_config['model']['init_args']['model']\n",
    "    model_title = yaml_config['model']['title']\n",
    "    output_dir = PROCESSED_DATA_DIR / DATA_VERSION / model_name\n",
    "    data_root = RAW_DATA_DIR / DATA_VERSION\n",
    "\n",
    "    embedding_extraction_strategies = yaml_config['embedding_extraction_strategies']\n",
    "    yaml_config['data']['init_args']['data_root'] = data_root\n",
    "    yaml_config['model']['init_args']['output_dir'] = output_dir\n",
    "    embeddings_directories = [item for item in output_dir.iterdir() if item.is_dir()]\n",
    "    for embeddings_directory in embeddings_directories:\n",
    "        print(str(embeddings_directory))\n",
    "        for file in tqdm(sorted(embeddings_directory.glob(\"*.parquet\"))):\n",
    "            df = pd.read_parquet(file)\n",
    "            file_id = int(file.stem.split(\"_\")[0])  # 0000 -> 0\n",
    "            df[\"id\"] = file_id\n",
    "            df.to_parquet(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7a92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_directory = embeddings_directories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e656427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b652144",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(sorted(embeddings_directory.glob(\"*.parquet\"))):\n",
    "    df = pd.read_parquet(file)\n",
    "    file_id = int(file.stem.split(\"_\")[0])  # 0000 -> 0\n",
    "    df[\"id\"] = file_id\n",
    "    df.to_parquet(dst / file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43e258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000005_embedding'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd19f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
