{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c297c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 00:16:39.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgelos.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mPROJ_ROOT path is: /app\u001b[0m\n",
      "/opt/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from gelos.gelosdatamodule import GELOSDataModule\n",
    "import yaml\n",
    "from gelos import config\n",
    "from lightning.pytorch import Trainer\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from gelos.config import PROJ_ROOT, PROCESSED_DATA_DIR, DATA_VERSION, RAW_DATA_DIR\n",
    "from terratorch.tasks import EmbeddingGenerationTask\n",
    "from gelos.features import LenientEmbeddingGenerationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c5338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.cli import instantiate_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ebce611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/app/gelos/configs/terramind_embedding_generation.yaml'), PosixPath('/app/gelos/configs/prithvi_eo_600m_embedding_generation.yaml'), PosixPath('/app/gelos/configs/prithvi_eo_300m_embedding_generation.yaml')]\n"
     ]
    }
   ],
   "source": [
    "yaml_config_directory = PROJ_ROOT / 'gelos' / 'configs'\n",
    "yaml_paths = list(yaml_config_directory.glob('*.yaml'))\n",
    "print(yaml_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3b9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = yaml_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a57863",
   "metadata": {},
   "source": [
    "## Run Embedding Generation step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970fcac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  class_path: gelos.gelosdatamodule.GELOSDataModule\n",
      "  init_args:\n",
      "    bands:\n",
      "      DEM:\n",
      "      - DEM\n",
      "      S1RTC:\n",
      "      - VV\n",
      "      - VH\n",
      "      S2L2A:\n",
      "      - COASTAL_AEROSOL\n",
      "      - BLUE\n",
      "      - GREEN\n",
      "      - RED\n",
      "      - RED_EDGE_1\n",
      "      - RED_EDGE_2\n",
      "      - RED_EDGE_3\n",
      "      - NIR_BROAD\n",
      "      - NIR_NARROW\n",
      "      - WATER_VAPOR\n",
      "      - SWIR_1\n",
      "      - SWIR_2\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    repeat_bands:\n",
      "      DEM: 4\n",
      "    transform:\n",
      "    - class_path: terratorch.datasets.transforms.FlattenTemporalIntoChannels\n",
      "    - class_path: albumentations.augmentations.geometric.resize.Resize\n",
      "      init_args:\n",
      "        height: 96\n",
      "        interpolation: 0\n",
      "        width: 96\n",
      "    - class_path: albumentations.pytorch.transforms.ToTensorV2\n",
      "    - class_path: terratorch.datasets.transforms.UnflattenTemporalFromChannels\n",
      "      init_args:\n",
      "        n_timesteps: 4\n",
      "embedding_extraction_strategies:\n",
      "  All Patches from April to June:\n",
      "  - start: 1\n",
      "    step: 1\n",
      "    stop: 2\n",
      "  All Steps of Middle Patch:\n",
      "  - start: 0\n",
      "    step: 1\n",
      "    stop: null\n",
      "  - start: 18\n",
      "    step: 1\n",
      "    stop: 19\n",
      "model:\n",
      "  class_path: terratorch.tasks.EmbeddingGenerationTask\n",
      "  init_args:\n",
      "    embed_file_key: filename\n",
      "    embedding_pooling: null\n",
      "    has_cls: false\n",
      "    layers:\n",
      "    - -1\n",
      "    model: terramind_v1_base\n",
      "    model_args:\n",
      "      merge_method: mean\n",
      "      modalities:\n",
      "      - S2L2A\n",
      "      - S1RTC\n",
      "      - DEM\n",
      "      pretrained: true\n",
      "    output_format: parquet\n",
      "    temporal_cfg:\n",
      "      temporal_pooling: keep\n",
      "      temporal_wrapper: true\n",
      "  title: Terramind V1 Base\n",
      "seed_everything: 0\n",
      "trainer:\n",
      "  accelerator: auto\n",
      "  callbacks: []\n",
      "  devices: auto\n",
      "  max_epochs: 0\n",
      "  num_nodes: 1\n",
      "  strategy: auto\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/terratorch/tasks/embedding_generation.py:67: UserWarning: GeoTIFF selected; 2D token embeddings (ViT) will be reshaped to [C, sqrt(num_tokens), sqrt(num_tokens)] after dropping CLS if present.\n",
      "  warnings.warn(\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/ibm-esa-geospatial/TerraMind-1.0-base/resolve/main/TerraMind_v1_base.pt \"HTTP/1.1 302 Found\"\n",
      "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "with open(yaml_path, \"r\") as f:\n",
    "        yaml_config = yaml.safe_load(f)\n",
    "\n",
    "print(yaml.dump(yaml_config))\n",
    "\n",
    "model_name = yaml_config['model']['init_args']['model']\n",
    "output_dir = PROCESSED_DATA_DIR / DATA_VERSION / model_name\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "data_root = RAW_DATA_DIR / DATA_VERSION\n",
    "\n",
    "# add variables to yaml config so it can be passed to classes\n",
    "yaml_config['data']['init_args']['data_root'] = data_root\n",
    "yaml_config['model']['init_args']['output_dir'] = output_dir\n",
    "\n",
    "# instantiate transform classes if they exist\n",
    "if \"transform\" in yaml_config[\"data\"][\"init_args\"].keys():\n",
    "      yaml_config[\"data\"][\"init_args\"][\"transform\"] = [\n",
    "            instantiate_class(args = (), init=class_path) for class_path in yaml_config[\"data\"][\"init_args\"][\"transform\"]\n",
    "      ]\n",
    "gelos_datamodule = GELOSDataModule(**yaml_config['data']['init_args'])\n",
    "task = LenientEmbeddingGenerationTask(**yaml_config['model']['init_args'])\n",
    "\n",
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "trainer = Trainer(accelerator=device, devices=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c684f47",
   "metadata": {},
   "source": [
    "### Inspect outputs of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf96cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gelos_datamodule.setup(stage=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2d716e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2L2A (4, 96, 96, 12)\n",
      "S1RTC (4, 96, 96, 2)\n",
      "DEM (4, 32, 32, 1)\n",
      "S2L2A torch.Size([12, 4, 96, 96])\n",
      "S1RTC torch.Size([2, 4, 96, 96])\n",
      "DEM torch.Size([1, 4, 96, 96])\n",
      "S2L2A torch.Size([12, 4, 96, 96])\n",
      "S1RTC torch.Size([2, 4, 96, 96])\n",
      "DEM torch.Size([1, 4, 96, 96])\n",
      "filename 000000\n",
      "file_id 0\n"
     ]
    }
   ],
   "source": [
    "for k, v in gelos_datamodule.dataset[0].items():\n",
    "    if k == \"image\":\n",
    "        for sensor, data in v.items():\n",
    "            print(sensor, data.shape)\n",
    "    else:\n",
    "        print(k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
